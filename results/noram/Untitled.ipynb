{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47868e13-0b2d-4daf-9bdd-090b1d84ea54",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 9\n",
    "\n",
    "kernel_size = 3\n",
    "kernel_size1 = 3\n",
    "kernel_size2 = 5\n",
    "# define network\n",
    "conv1toconv2 = 16\n",
    "conv2toconv3 = 32\n",
    "conv3toconv4 = 64\n",
    "conv4toconv5 = 128\n",
    "conv5toconv6 = 64\n",
    "input_channels = 3\n",
    "residual = 256\n",
    "conv6tolin1 = 32\n",
    "dropout_rate = 0.5\n",
    "class NeuralNetwork(nn.Module):\n",
    "\tdef __init__(self):\n",
    "    \tsuper(NeuralNetwork, self).__init__()\n",
    "    \t#Takes in 3, 144, 496\n",
    "    \tself.conv1 = nn.Conv2d(input_channels,conv1toconv2,kernel_size2)\n",
    "    \tself.conv2 = nn.Conv2d(conv1toconv2,conv2toconv3,kernel_size)\n",
    "    \tself.bn2 = nn.BatchNorm2d(conv2toconv3)\n",
    "    \tself.conv3 = nn.Conv2d(conv2toconv3,conv3toconv4,kernel_size)\n",
    "    \tself.conv4 = nn.Conv2d(conv3toconv4,conv4toconv5 ,kernel_size)\n",
    "    \tself.bn4 = nn.BatchNorm2d(conv4toconv5)\n",
    "    \tself.conv5 = nn.Conv2d(conv4toconv5,residual,kernel_size)\n",
    "    \t#self.conv6 = nn.Conv2d(conv5toconv6,conv6tolin1,kernel_size)\n",
    "    \tself.pool = nn.AvgPool2d(2,2)\n",
    "    \tself.poolmax = nn.MaxPool2d(2,2)\n",
    "    \tself.FC1 = nn.Linear(6*residual, residual) #256\n",
    "    \tself.FC2 = nn.Linear(residual, residual) #256,512\n",
    "    \tself.bn1 = nn.BatchNorm1d(residual)  # For fully connected layers\n",
    "    \t#self.FC3 = nn.Linear(256, 256) #512,256\n",
    "    \tself.FC4 = nn.Linear(residual, num_classes) #256,num_classes\n",
    "    \tself.dropout = nn.Dropout(dropout_rate)\n",
    "   \t \n",
    "    \t# Create residual blocks\n",
    "    \tself.resblock1 = ResidualBlock(residual, residual, kernel_size)\n",
    "    \tself.resblock2 = ResidualBlock(residual, residual, kernel_size)\n",
    "    \tself.resblock3 = ResidualBlock(residual, residual, kernel_size)\n",
    "    \tself.resblock4 = ResidualBlock(residual, residual, kernel_size)\n",
    "    \tself.resblock5 = ResidualBlock(residual, residual, kernel_size)\n",
    "    \tself.resblock6 = ResidualBlock(residual, residual, kernel_size)\n",
    "    \t#self.resblock7 = ResidualBlock(residual, residual, kernel_size)\n",
    "    \t#self.resblock8 = ResidualBlock(residual, residual, kernel_size)\n",
    "    \t#self.resblock9 = ResidualBlock(residual, residual, kernel_size)\n",
    "    \t#self.resblock10 = ResidualBlock(residual, residual, kernel_size)\n",
    "        # self.resblock7 = ResidualBlock(conv4toconv5, conv4toconv5)\n",
    "    \t#self.resblock8 = ResidualBlock(conv4toconv5, conv2toconv3)\n",
    "    \t#self.resblock9 = ResidualBlock(conv2toconv3, conv4toconv5)\n",
    "    \t#self.resblock10 = ResidualBlock(conv4toconv5, residual)\n",
    "    \t#self.resblock11 = ResidualBlock(residual, residual)\n",
    "    \t#self.resblock12 = ResidualBlock(residual, residual)\n",
    "\n",
    "\tdef forward(self, x):\n",
    "    \tx = self.conv1(x) #140x492\n",
    "    \tx = F.relu(x)\n",
    "    \t#print(x.shape)\n",
    "    \tx = self.poolmax(x) #70x246\n",
    "   \t \n",
    "    \t#print(x.shape)\n",
    "    \tx = self.conv2(x) #68x244\n",
    "    \tx = self.bn2(x)\n",
    "    \tx = F.relu(x)\n",
    "    \tx = self.pool(x) #34x122\n",
    "   \t \n",
    "    \tx = self.conv3(x) #68x244\n",
    "    \tx = F.relu(x)\n",
    "    \tx = self.pool(x) #34x122\n",
    "   \t \n",
    "    \tx = self.conv4(x) #68x244\n",
    "    \tx = self.bn4(x)\n",
    "    \tx = F.relu(x)\n",
    "    \tx = self.pool(x) #34x122\n",
    "   \t \n",
    "    \tx = self.conv5(x) #68x244\n",
    "    \tx = F.relu(x)\n",
    "    \tx = self.pool(x) #34x122\n",
    "   \t \n",
    "    \t#print(\"f res\",x.shape)\n",
    "    \t# Apply residual blocks\n",
    "    \tx = self.resblock1(x)\n",
    "    \tx = self.resblock2(x)\n",
    "    \tx = self.resblock3(x)\n",
    "    \tx = self.resblock4(x)\n",
    "    \tx = self.resblock5(x)\n",
    "    \tx = self.resblock6(x)\n",
    "    \t#x = self.resblock7(x)\n",
    "    \t#x = self.resblock8(x)\n",
    "    \t#x = self.resblock9(x)\n",
    "    \t#x = self.resblock10(x)\n",
    "    \t#x = self.resblock7(x)\n",
    "    \t#x = self.resblock8(x)\n",
    "    \t#x = self.resblock9(x)\n",
    "    \t#x = self.resblock10(x)\n",
    "    \t#x = self.resblock11(x)\n",
    "    \t#x = self.resblock12(x)\n",
    "    \t#print(x.shape)\n",
    "    \tx = self.pool(x) #17x61\n",
    "    \t#print(x.shape)\n",
    "    \tx = torch.flatten(x,1) #self.flatten = nn.Flatten()\n",
    "    \t#print(x.shape)\n",
    "    \t#print(2*7*residual)\n",
    "    \tx = self.FC1(x)\n",
    "    \tx = F.relu(x)\n",
    "    \tx = self.dropout(x)\n",
    "    \tx = self.FC2(x)\n",
    "    \tx = self.bn1(x)\n",
    "    \t#x = self.dropout(x)\n",
    "    \tx = F.relu(x)\n",
    "    \t#x = self.FC3(x)\n",
    "    \t#x = F.relu(x)\n",
    "    \t#x = self.dropout(x)\n",
    "    \tx = self.FC4(x)\n",
    "   \t \n",
    "    \treturn x\n",
    "\n",
    "net = NeuralNetwork()\n",
    "net.to(device);\n",
    "#print(net)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
